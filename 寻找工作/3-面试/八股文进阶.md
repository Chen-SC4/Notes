# 八股文进阶

## 1. 分布式锁 (基于 Redis)

### 锁的互斥性

在加锁时，使用 `Redis` 中的 `Set nx` 指令实现锁的互斥性。`nx` 表示只有键**不存在**时才执行 `Set` 操作，表示 `Not Exists`。

在解锁时，需要先判断锁是否是当前线程的锁，然后再进行解锁操作；此时需要保证 `判断 + 释放` 这两步操作的原子性，需要使用 `Lua` 脚本来实现。

- 为什么 `Set nx` 不用使用 `Lua` 脚本？

因为 Redis 执行命令的模块是单线程的，并且 `Set nx` 是单个指令，具有天然的原子性，而解锁时需要首先 `Get` 得到锁，然后判断锁是否是需要释放的锁，最后进行释放操作 (`Del`)，这涉及到多个指令，并且这多个指令需要**同时成功**或者**同时失败** (原子性)，所以需要使用 `Lua` 脚本。

- 在一个线程获取到锁之后，线程异常退出了，无法释放锁，该怎么办？

需要给锁设置一个过期时间，否则线程异常退出，并且无法释放锁，资源就永远无法释放了；通常 `Set ex` 来设置过期时间。

- 既然锁是有过期时间的，那么如果一个线程的业务本身就需要很长时间，但是执行一半，锁过期了，该怎么办？

需要使用**看门狗机制**，需要有一个看门狗线程来定时给锁重置过期时间，保证业务执行完成前锁不会被自动释放。

同时这个看门狗线程需要**绑定**业务线程，因为如果业务线程异常退出，而看门狗线程不知道的话，锁就又无法释放了。看门狗线程可以是业务线程的**守护线程**，也可以用其他的实现方式。

### 锁的可重入性

参考其他锁的设计中是如何实现可重入性的：

- `synchronized` 为每个对象关联一个 `Monitor`，`Monitor` 中有一个锁计数器字段，每当锁重入时，计数器字段加一，释放时，计数器字段减一。
- `ReentrantLock` 基于 `AQS` 实现，利用 `AQS` 中的 `state` 字段，每当锁重入时，`state` 字段加一，释放时，`state` 字段减一。

综合上面的两个设计，可以看出要实现可重入性，需要一个**锁计数器字段**。那么分布式锁该如何设置一个锁计数器字段呢？

1. 使用哈希结构 (Redission)

以要锁住的资源为 `Key`、以 `线程 ID#UUID` 为 `Field`、以重入次数 (锁计数器字段) 为 `Value`。每当锁重入时，`Value` 字段加一，释放时，`Value` 字段减一。不过相应的，此时就不是 `Set nx` 了，而是 `HSet nx`。

- 为什么 `Field` 是线程 ID + UUID 呢？

因为在集群环境下，线程 ID 可能会发生重复，拼接上 UUID，就几乎不可能发生重复了。

2. 本地使用 `ConcurrentHashMap`

在 `Redis` 中仍然使用 `Set nx` 来上锁，但是在获取到锁之后，在服务端的本地维护一个 `ConcurrentHashMap` 来记录当前锁的重入次数 (锁计数器)。在第一次上锁时，在 `ConcurrentHashMap` 中创建锁的对应字段，在之后重入时，`ConcurrentHashMap` 中的锁对应的字段加一，释放时，对应字段减一。

这种方式在每次重入时不再需要 `Redis` 进行维护了，从而减少了网络 `IO` 的开销，速度无疑是比第一种方法快的，但是在生产环境下，我们仍然很少会用这种方法。

## 2. MySQL 中的三种日志

### Undo Log

#### 保证事务的原子性

MySQL 支持事务，其中事务的四大特性中有一条是原子性：事务中的所有操作要么同时成功，要么同时失败。如果中间有操作执行失败，那么已经执行的操作需要回滚。

> MySQL 是如何实现原子性的呢？数据该如何回滚到未修改的版本？

MySQL 需要保存数据的不同版本，每次进行修改操作时，MySQL 需要保存原始的数据版本。不同的版本之间通过指针连接，形成一个链表结构 (Undo Log 版本链)。也就是说 MySQL 会在修改的过程中，将旧版本的数据保存至 Undo Log 中，如果事务需要进行回滚，MySQL 可以通过 Undo Log 找到数据的旧版本信息。

#### 实现 MVCC (保证事务的隔离性)

事务有四种隔离级别：读未提交、读已提交、可重复读、串行化。其中读未提交无需实现，串行化通过加锁实现；剩下的读已提交和串行化则是通过 MVCC 实现。Undo Log 在其中起到的作用就是：当事务读到另一个事务的数据时，如果该事务未提交或者当前的隔离级别不允许读取，则需要通过 Undo Log 找到旧版本的数据再读取。

### Redo Log

MySQL 的数据是保存在磁盘上的，但是磁盘的 IO 开销是非常大的，为了加快速度，一个非常常见的做法就是引入**缓存**。在 MySQL 中，这个缓存是一个缓存池 Buffer Pool。在查询数据时，如果缓存未命中，则会从磁盘中拿出一页的数据 (局部性原理)，然后放入缓存中。

在写数据时，也是先把数据写入到缓存中，然后将该页标记为脏页 (Dirty)，在后续某个时间再进行脏页的刷盘。

> Buffer Pool 是在内存中的，如果 Buffer Pool 中的脏页在刷盘之前，MySQL 就异常了，那么数据丢失该怎么办？

为了解决这个问题 MySQL (InnoDb) 引入了 Redo Log。每次对磁盘也做了什么更新操作都会记录到 Redo Log 中。在事务提交时将 Redo Log 刷盘，如果出现 Buffer Pool 数据未刷盘就异常的情况，可以在再次启动时读取 Redo Log 来恢复数据。

> 为什么不在修改完了 Buffer Pool 之后就直接刷盘呢 (写直达)？

因为 Buffer Pool 的刷盘是随机 IO，因为修改数据的位置不一定是顺序的；而 Redo Log 的刷盘是顺序 IO，因为都是修改 Redo Log (在 Redo Log 中新增信息)。

在一个事务的执行中，包含有 Redo Log 的刷盘 (设置一个相关参数)，只有 Redo Log 完成刷盘，此次事务才算成功。

### Bin Log

Redo Log 记录的数据库的修改，但是 Redo Log 的结构其实是一个循环结构，旧的数据会被新的数据覆盖；这个特性的好处是 Redo Log 所占用的空间是固定的，同时也局限了 Redo Log 只负责记录事务提交之后没有被刷盘的数据，用来保证已提交事务的掉电不丢失。

但是如果我们需要做数据备份、主从复制、数据恢复 (全量恢复) 这种操作，是无法通过 Redo Log 完成的，因为 Redo Log 不会记录所有的数据库数据。

如果我们要记录数据库层面上的种种修改，我们需要用到 Bin Log。Bin Log 记录数据库中数据的修改、数据库中表结构的修改。

> Bin Log 和 Redo Log 都会记录数据的修改，它们之间的一致性是如何保证的？如果 Redo Log 刷盘了，但是 Bin Log 没有刷盘怎么办？

为了解决两个日志的一致性问题，MySQL 采用了**二段式提交机制**。其流程如下：

1. 开启事务
2. 更新数据
3. Prepare (写入 Redo Log)
4. 写入 Bin Log
5. Commit (将 Redo Log 设置为 Commit)

如果在 1、2、3 步出现异常，直接回滚事务。如果在 4 步出现异常，此时还是会回滚事务，因为 Redo Log 和 Bin Log 数据不一致。如果在 5 步出现异常，此时 Redo Log 成功写入 (但是没有被设置为 Commit)，同时可以找到对应的 Bin Log (说明 4 步执行完成)，那么直接将 Redo Log 设置为 Commit 并提交事务。